meta:
  direction: ltr
  language: en

basic:
  name: Dawei Zhang
  title: Senior DevOps Engineer
  avatar:
    show: false                      # show or hide avatar
    path: /assets/images/profile.png # file path or link to your avatar

contact:
  location: Toronto, Canada
  email: davyzhang325@gmail.com
  phone: 6478790325
  website: https://davyzhang3.github.io/online-resume/


  github: davyzhang3
  gitlab: 
  bitbucket: 
  git: 
  leetcode: 
  codeforces: 
  codewars: 
  topcoder: 
  huggingface: 
  codepen: 
  tryhackme: 

  googlescholar: 
  researchgate: 
  orcid: 
  figshare: 
  kaggle: 

  medium: 
  wordpress: 
  blogger: 
  devto: 

  figma: 
  behance: 
  dribbble: 
  artstation: 
  pixiv: 
  pinterest: 
  producthunt: 

  linkedin: 
  indeed: 
  xing: 
  fiverr: 
  freelancer: 

  wechat: 
  whatsapp: 
  telegram: 
  messenger: 
  line: 
  viber: 
  threema: 
  signal: 
  wire: 

  stackoverflow: 
  stackexchange: 
  quora: 
  zhihu: 
  goodreads: 
  strava: 
  wikipedia: 
  twitter: 
  x: 
  mastodon: 
  threads: 
  vk: 
  weibo: 
  instagram: 
  unsplash: 
  _500px: 
  youtube: 
  tiktok: 
  snapchat: 
  twitch: 

profile:
  show: true
  order: 1
  title: Profile
  description: |
    Senior DevOps Engineer and Product Owner at Weclouddata, adept at optimizing cloud infrastructure and implementing CI/CD pipelines. Demonstrated expertise in AWS and Azure, deploying and managing cloud resources with IaC tools. Strong collaborator with a proven track record in mentoring and developing educational programs in DevOps.

experience:
  show: true
  order: 2
  title: Experiences
  description: |
    Work experience in DevOps, Data Engineering, and Cloud Infrastructure across multiple industries and clients.
  items:
    - company: Weclouddata
      link:
      tags: Full-time
      date: December 2021 - Current
      role: Senior DevOps Engineer | Product Owner
      location: Toronto, Canada
      description: |
        + The administrator of the company's GitHub organization, AWS, Azure and GCP accounts.
        + Managed permissions for over 100 users in both AWS and Azure organization accounts.
        + Set up and maintained the infrastructure of the dev and prod environments of the company websites with Terraform and CloudFormation. The environment covered AWS EKS, AWS Route 53, AWS Certificate Manager, Auto Scaling Group, Application Load Balancer, VPC, AWS CodePipeline, Launch Template, etc.
        + Configured multiple AWS EKS cluster environments from scratch using Terraform.
        + Installed and maintained ArgoCD, Prometheus, Grafana, cert-manager, metrics-server and NGINX Ingress Controller on AWS EKS cluster to monitor the infrastructure and applications.
        + Used K9s and kubectl for efficient management and troubleshooting of Kubernetes clusters.
        + Adopted GitOps practices using ArgoCD to manage application deployments on AWS EKS, improving deployment speed and reliability.
        + Managed Domain Names with AWS Route 53 and GoDaddy.
        + Used GitHub Actions to create CI pipelines for various applications, automating testing and deployment processes.
        + Previously managed the company's AWS infrastructure using AWS CloudFormation. Later transitioned to Terraform for managing infrastructure across multiple cloud providers, enhancing scalability and maintainability.
        + Reduced compute resource costs by approximately 30-60% through strategic purchasing of Savings Plans, spot instances, and consistent monitoring using AWS CloudWatch and AWS Cost Explorer.
        + Enhanced security by implementing AWS IAM best practices, including the use of roles, policies, and multi-factor authentication (MFA).
        + Set up VPC to isolate different environments and implemented security groups and network ACLs to control inbound and outbound traffic.
        + Configured AWS and Azure accounts to meet the ISO27001 compliance standards, ensuring data security and regulatory adherence.
        + Version controlled infrastructure code using GitHub, enabling collaboration and tracking of changes.
        + Built and maintained an internal data warehouse, collecting data from multiple databases, and third-party applications using Airbyte.
        + Collaborated with colleagues to develop and maintain a serverless application called Event Manager using AWS Lambda. The application enabled the publishing of 20 posts on different channels across 6 platforms with a few clicks, reducing repetitive work by 90%, and saving significant time for the company.
        + Installed and maintained data pipeline tools such as Airbyte, DBT, MageAI, and Apache Airflow on EC2 instances and AWS EKS.
        + Deployed well-trained machine learning models and AI apps on AWS EKS.
        + Conducted labs for DevOps courses, assisting dozens of students in transitioning to DevOps Engineering roles.
        + Designed and created lab materials covering Infrastructure as Code, CI/CD pipeline tools, Linux Fundamentals, AWS, GitOps, and Networks.
        + Revised syllabus and lecture slides based on student feedback, ensuring an improved learning experience.
        + Provided guidance, explanations, and problem-solving assistance to students.
        + Designed and developed a Cloud Engineer course covering core services on both AWS and Azure, such as EC2, S3, VPC, RDS, Lambda, Azure VM, VMSS, Azure Storage Account, Azure CosmosDB, and Azure Functions.
        + Managed the development of the course by creating roadmaps, having daily stand-ups, and using GitHub projects. Actively collaborate with colleagues to have the course ready in 2 months.
        + Hired program TAs and instructors.

    - company: Beamdata
      link:
      tags: Contract
      date: February 2022 - March 2025
      role: Data Engineer | DevOps Engineer
      location: Toronto, Canada
      description: |
        + Project Overview: Configuration and Maintenance of the Data Warehouse and Infrastructure for Barrett Jackson.
        + Automated data collection by building data pipelines with Azure Data Factory from over 10 sources, including SQL Server, SparkPost, Ongage, Google Analytics, and Salesforce, and storing it in the Synapse data warehouse.
        + Set up and managed various Azure resources, such as Azure Virtual Machines, Azure Key Vault, Azure Data Factory, Azure Storage Account, and Azure Entra ID, in both development and production environments with Terraform.
        + Devised cost-saving strategies, reducing infrastructure expenses by up to 65%.
        + Implemented data warehouse security measures, including data masking, data backup, and firewall configurations.
        + Configuration and maintenance of the data warehouse and infrastructure.
        + Established CI/CD pipelines with GitHub Actions to enhance developer efficiency.
        + Documented development and configuration processes for future reference and consistency.

    - company: Beamdata
      link:
      tags: Contract
      date: July 2024 - November 2024
      role: DevOps Engineer
      location: Toronto, Canada
      description: |
        + Project Overview: Enhanced infrastructure and workflows for the data team at The Globe and Mail.
        + Integrated MLFlow to optimize version control of machine learning models.
        + Debugged the existing AWS Fargate service.
        + Implemented a load test with Locust and generated a report against the API.
        + Tested and containerized a chatbot application, and delivered it to the client.
        + Scanning the tokens and secrets in the GitHub organization of the client with Trufflehog.

    - company: Beamdata
      link:
      tags: Contract
      date: November 2022 - March 2023
      role: DevOps Engineer
      location: Toronto, Canada
      description: |
        + Project Overview: Infrastructure Configuration and Maintenance for a healthcare company.
        + Managed infrastructure scripts using GitHub.
        + Established and maintained an end-to-end CI/CD pipeline for code deployment on AWS EC2 servers, utilizing AWS CodePipeline.
        + Provisioned servers and deployed features using AWS CloudFormation.
        + Monitored infrastructure metrics with AWS CloudWatch, and implemented notifications through AWS SNS.
        + Configured domain name setup using AWS Route 53.
        + Implemented self-healing capabilities for the application by utilizing AWS Auto Scaling groups.
        + Infrastructure configuration and maintenance.

    - company: Beamdata
      link:
      tags: Contract
      date: November 2020 - November 2021
      role: Data Engineer Consultant | Machine Learning Engineer
      location: Toronto, Canada
      description: |
        + Client: Samsung Electronics Canada - New product launch prediction
          + Worked closely with the advanced analytics team on the price forecasting for launched projects.
          + Designed an ETL pipeline to migrate and data from MySQL Server to Pandas Dataframe with SQLAlchemy.
          + Predicted future value of number of stores opening using ARIMA in Jupyter Notebook. Then predicted future daily sales based on predicted features using Random Forest and XGBoost, minimized the Mean Absolute Percentage Error to 14%.
          + Performed feature engineering by combining old features and extra pandemic feature and holiday flags for model preparation, providing more precise and reliable data sources for the next steps of sales prediction.
          + Presented results and visualized data using Tableau and provided business insight.
          + Took the responsibility as a scrum master to communicate with clients, summarized notes on Confluence, made plans and allocated tasks using JIRA.
          + Followed Agile methodologies to update progress with teammates and manage schedules.
        + Client: Online Education Platform - Business Partnership Platform
          + Gathered and analyzed information on different online resources of potential partners in order to open new overseas branches for clients.
          + Developed a scraper in order to gather potential customer profile from LinkedIn and Google using Selenium, SQLAlchemy, Pandas and BeautifulSoup and deployed it on an EC2 Server.
          + Designed an ETL data pipeline to extract and migrate semi-structured data from S3 bucket to Neo4j and Postgres Database.
          + Added a multithreading technique to ETL and scraping to increase their speed by 8 times.
          + Automated the daily ETL process using Apache Airflow, successfully speeded up the data collection performance and improved efficiency.
        + Client: Online Education Platform - Cloud Platform Management
          + Managed user-level permissions for Apache Airflow, Jenkins and Linux systems.

project:
  show: false
  order: 3
  title: Projects
  description: |
    Selected projects demonstrating DevOps, Data Engineering, and Cloud expertise.
  items:
    - name: Event Manager (Weclouddata)
      link:
      tags: AWS Lambda, Serverless
      date: 2022
      description: |
        + Developed a serverless app to automate multi-channel post publishing, reducing repetitive work by 90%.
    - name: Internal Data Warehouse (Weclouddata)
      link:
      tags: Airbyte, DBT, MageAI, Airflow
      date: 2022
      description: |
        + Built and maintained data pipelines and warehouse for analytics and reporting.
    - name: Cloud Engineer Course (Weclouddata)
      link:
      tags: Education, AWS, Azure
      date: 2023
      description: |
        + Designed and developed a course covering AWS and Azure core services, managed roadmap and team.

skill:
  show: true
  order: 4
  title: Skills
  description: |
    Technical and cloud skills relevant to DevOps, Data Engineering, and Cloud Infrastructure.

  groups:
    - name: AWS Services
      item:
        - AWS VPC
        - AWS EC2
        - AWS EKS
        - AWS IAM
        - AWS CloudWatch
        - AWS Lambda
        - AWS Secrets Manager
        - AWS CloudFormation
        - AWS S3
        - AWS RDS
        - AWS CloudTrail
        - AWS CodePipeline
        - AWS CodeCommit
        - AWS CodeArtifact
        - AWS CodeBuild
        - AWS Certificate Manager
        - AWS Route53
        - AWS API Gateway
        - AWS Step Functions
        - AWS Backup
        - AWS SNS
        - AWS Systems Manager
        - AWS ECR
        - AWS ECS
        - AWS Billing and Cost Management
    - name: Azure Services
      item:
        - Microsoft Entra ID
        - Azure Key Vault
        - Azure Storage Accounts
        - Azure Data Factory
        - Azure Functions
        - Azure Synapse
        - Azure Cosmos DB
        - Azure PostgreSQL Servers
        - Azure Virtual Machines
        - VMSS
        - Azure Application Load Balancer
        - Azure Container Apps
        - Azure Container Registry
    - name: Programming
      item:
        - Python
        - Go
        - SQL
        - Bash
        - Git
        - JavaScript
        - HTML
        - CSS
    - name: DevOps Tools
      item:
        - Terraform
        - Ansible
        - Docker
        - Kubernetes
        - K9s
        - Jenkins
        - GitHub Actions
        - ArgoCD
        - Cert-manager
        - NGINX
    - name: Data & Analytics
      item:
        - Apache Airflow
        - Airbyte
        - Pandas
        - Numpy
        - Prometheus
        - Tableau
        - Grafana
    - name: Databases
      item:
        - MySQL
        - PostgreSQL
        - MongoDB
    - name: Others
      item:
        - Linux
        - Mac
        - Windows

education:
  show: true
  order: 5
  title: Education
  description: |
    Academic background in Data Science and Engineering.
  items:
    - institution: Toronto Institute of Data Science and Technology
      link:
      date: 2021
      major: Data Science
      degree: Diploma
      description: |
        Data Science Diploma
    - institution: Ryerson University
      link:
      date: 2019
      major: Electrical Engineering
      degree: Bachelor of Engineering
      description: |
        Bachelor of Engineering in Electrical Engineering

certificate:
  show: true
  order: 6
  title: Certificates
  description: |
    Professional certifications in DevOps and Cloud.
  items:
    - name: Advanced GitOps Certification
      issuer: 
      date: 
      link:
      description: |
        Advanced GitOps Certification
    - name: "HashiCorp Certified: Terraform Associate (003)"
      issuer: HashiCorp
      date: 
      link:
      description: |
        HashiCorp Certified: Terraform Associate (003)

patent:
  show: false
  order: 9
  title: Patents
  description: |
    # ...existing code...

organization:
  show: false
  order: 10
  title: Organizations
  description: |
    # ...existing code...

language:
  show: true
  order: 11
  title: Languages
  description: |
    Proficient in English and Chinese (Mandarin).
  items:
    - idiom: English
      level: Professional
    - idiom: Chinese (Mandarin)
      level: Native
